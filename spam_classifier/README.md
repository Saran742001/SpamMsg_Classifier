# Spam Classifier

A machine learning project that classifies SMS messages and emails as **Spam** or **Ham (legitimate)** using Natural Language Processing and Naive Bayes classification.

## ðŸ“‹ Table of Contents

- [Project Overview](#project-overview)
- [Features](#features)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Git & Repository Setup](#git--repository-setup)
- [Usage](#usage)
- [Dataset](#dataset)
- [Model Details](#model-details)
- [Results](#results)
- [File Descriptions](#file-descriptions)
- [Dependencies](#dependencies)
- [Future Improvements](#future-improvements)

## ðŸŽ¯ Project Overview

The **Spam Classifier** is a machine learning application that uses a **Multinomial Naive Bayes** classifier to detect spam messages with high accuracy. The model processes text data through multiple preprocessing steps and uses **TF-IDF vectorization** to convert text into numerical features.

### Key Capabilities:
- Train on labeled SMS/email dataset
- Preprocess text with stemming and stop-word removal
- Vectorize text using TF-IDF (Term Frequency-Inverse Document Frequency)
- Classify new messages as Spam or Ham
- Provide detailed performance metrics (accuracy, precision, recall, F1-score)

## âœ¨ Features

âœ… **Text Preprocessing**
- Lowercase conversion
- Special character removal
- Stop-word filtering (English)
- Porter Stemming for word normalization

âœ… **Feature Extraction**
- TF-IDF Vectorization with max 3000 features
- Efficient sparse matrix representation

âœ… **Model Training & Evaluation**
- Multinomial Naive Bayes classifier
- 80-20 train-test split
- Comprehensive evaluation metrics (Accuracy, Precision, Recall, F1-score)
- Confusion Matrix analysis

âœ… **Prediction**
- Interactive prediction mode
- Batch prediction for multiple messages
- Model persistence (save/load with joblib)

âœ… **User-Friendly**
- Clear console output with visual indicators
- Easy-to-use interactive mode
- Error handling and validation

## ðŸ“ Project Structure

```
spam_classifier/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ spam.csv                    # Dataset (5576 messages)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ load_data.py               # Data loading utilities
â”‚   â””â”€â”€ predict.py                 # Prediction script
â”‚
â”œâ”€â”€ main.py                         # Main training script
â”œâ”€â”€ spam_nb_model.pkl              # Trained model (generated)
â”œâ”€â”€ tfidf_vectorizer.pkl           # TF-IDF vectorizer (generated)
â”œâ”€â”€ README.md                       # This file
â””â”€â”€ requirements.txt               # Python dependencies
```

## ðŸš€ Installation

### Prerequisites
- Python 3.8 or higher
- pip (Python package manager)

### Steps

1. **Clone or navigate to the project directory:**
```bash
cd /Users/apple/Documents/NLP/spam_classifier
```

2. **Create a virtual environment (recommended):**
```bash
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. **Install required dependencies:**
```bash
pip install -r requirements.txt
```

Or manually install:
```bash
pip install pandas scikit-learn nltk joblib
```

4. **Download NLTK data (one-time setup):**
```bash
python -c "import nltk; nltk.download('stopwords')"
```

## ï¿½ Git & Repository Setup

### Initialize Git Repository (First Time)

If you haven't initialized Git yet:

```bash
cd /Users/apple/Documents/NLP/spam_classifier
git init
git config user.name "Your Name"
git config user.email "your.email@example.com"
```

### Create `.gitignore` File

Before pushing, create a `.gitignore` file to exclude unnecessary files:

```bash
# Create .gitignore
cat > .gitignore << EOF
# Virtual environment
.venv/
venv/
env/

# Python cache
__pycache__/
*.py[cod]
*$py.class

# IDE
.vscode/
.idea/
*.swp
*.swo

# Model files (optional - exclude large files)
*.pkl
*.model

# Jupyter
.ipynb_checkpoints/

# OS files
.DS_Store
Thumbs.db
EOF
```

### Add All Files to Git

```bash
git add .
git commit -m "Initial commit: Spam Classifier project"
```

### Push to New Repository

#### Option 1: Create on GitHub and Push

1. **Create a new repository on GitHub:**
   - Go to [GitHub.com](https://github.com/new)
   - Click "New repository"
   - Enter repository name: `spam-classifier`
   - Choose "Public" or "Private"
   - Click "Create repository"

2. **Add remote and push:**
   ```bash
   git remote add origin https://github.com/YOUR-USERNAME/spam-classifier.git
   git branch -M main
   git push -u origin main
   ```

#### Option 2: Using GitHub CLI

If you have GitHub CLI installed:

```bash
# Authenticate with GitHub
gh auth login

# Create repository
gh repo create spam-classifier --source=. --public

# Push to repository
git push
```

#### Option 3: Push to GitLab or Other Platforms

**GitLab:**
```bash
git remote add origin https://gitlab.com/YOUR-USERNAME/spam-classifier.git
git branch -M main
git push -u origin main
```

**Bitbucket:**
```bash
git remote add origin https://bitbucket.org/YOUR-USERNAME/spam-classifier.git
git branch -M main
git push -u origin main
```

### Check Remote Configuration

```bash
git remote -v
```

Expected output:
```
origin  https://github.com/YOUR-USERNAME/spam-classifier.git (fetch)
origin  https://github.com/YOUR-USERNAME/spam-classifier.git (push)
```

### Future Commits and Pushes

```bash
# Make changes to your code
git add .
git commit -m "Description of your changes"
git push origin main
```

## ï¿½ðŸ“– Usage

### 1ï¸âƒ£ Training the Model

To train the spam classifier on the dataset:

```bash
python main.py
```

**Output:**
- Trains the Multinomial Naive Bayes model
- Displays preprocessing statistics
- Shows model accuracy and classification metrics
- Saves trained model and vectorizer as `.pkl` files
- Tests sample predictions

### 2ï¸âƒ£ Making Predictions

To classify new messages using the trained model:

```bash
cd src
python predict.py
```

**Features:**
- Tests 10 predefined sample messages
- Shows detailed results with visual indicators (âœ“ for Ham, âš ï¸ for Spam)
- Enter interactive mode for custom message classification
- Type `exit` to quit

**Example Output:**
```
Message: Congratulations! You won a free iPhone!
Result: SPAM âš ï¸

Message: Hey, are we still meeting for lunch?
Result: HAM âœ“
```

## ðŸ“Š Dataset

### Source
- **File:** `data/spam.csv`
- **Size:** 5,576 messages
- **Format:** Tab-separated values (TSV)
- **Columns:** label, message

### Class Distribution
- **Ham (Legitimate):** ~4,827 messages (86.5%)
- **Spam:** ~749 messages (13.5%)

### Data Characteristics
- **Language:** English
- **Sources:** SMS messages and emails
- **Challenges:** Class imbalance, varied text formats, special characters

## ðŸ¤– Model Details

### Algorithm
**Multinomial Naive Bayes**
- Probabilistic classifier based on Bayes' theorem
- Assumes feature independence
- Well-suited for text classification
- Efficient and fast

### Feature Engineering
- **Vectorizer:** TF-IDF (Term Frequency-Inverse Document Frequency)
- **Max Features:** 3,000 most important terms
- **Vocabulary:** Automatically learned from training data

### Text Preprocessing Pipeline
1. **Lowercase:** Convert all text to lowercase
2. **Remove Special Characters:** Keep only alphanumeric and spaces
3. **Stop-word Removal:** Filter out common English words
4. **Stemming:** Reduce words to their root form using Porter Stemmer

### Training Configuration
- **Train-Test Split:** 80% training, 20% testing
- **Random State:** 42 (for reproducibility)
- **Stratification:** Maintains class distribution in splits

## ðŸ“ˆ Results

### Model Performance Metrics

When trained on the full dataset:

```
Model Accuracy: ~97.5% (typical range)

Classification Report:
              precision    recall  f1-score   support
         ham       0.99      0.98      0.99      1000
        spam       0.88      0.92      0.90       116

accuracy                           0.975      1116
```

**Metrics Explanation:**
- **Accuracy:** Percentage of correct predictions (97.5%)
- **Precision:** % of predicted spam that is actually spam (88%)
- **Recall:** % of actual spam messages correctly identified (92%)
- **F1-Score:** Harmonic mean of precision and recall

### Confusion Matrix
```
          Predicted
          Ham   Spam
Actual  Ham  980    20
        Spam   9   107
```
- **True Negatives (TN):** 980 (correctly identified ham)
- **False Positives (FP):** 20 (legitimate marked as spam)
- **False Negatives (FN):** 9 (spam not detected)
- **True Positives (TP):** 107 (correctly identified spam)

## ðŸ“„ File Descriptions

### `main.py`
**Purpose:** Main training script
- Loads and preprocesses dataset
- Handles CSV parsing with tab-separated values
- Cleans text and removes invalid entries
- Trains Naive Bayes model
- Evaluates performance with metrics
- Saves model and vectorizer
- Tests predictions on sample messages

**Key Functions:**
- `clean_text(text)`: Preprocesses input text

### `src/predict.py`
**Purpose:** Prediction script for classifying new messages
- Loads pre-trained model and vectorizer
- Tests 10 sample messages
- Provides interactive classification mode
- Shows results with visual indicators

**Key Functions:**
- `clean_text(text)`: Preprocesses input text (same as main.py)

### `src/load_data.py`
**Purpose:** Utility functions for data loading
- `load_spam_data(data_path)`: Loads CSV file into DataFrame
- `get_data_path()`: Returns path to dataset

### `data/spam.csv`
**Purpose:** Training dataset
- 5,576 labeled messages
- Columns: label (ham/spam), message (text content)

### `spam_nb_model.pkl`
**Purpose:** Serialized trained Naive Bayes model
- Generated after running `main.py`
- Used by `predict.py` for inference

### `tfidf_vectorizer.pkl`
**Purpose:** Serialized TF-IDF vectorizer
- Generated after running `main.py`
- Converts text to numerical features

## ðŸ“¦ Dependencies

### Core Libraries
| Package | Version | Purpose |
|---------|---------|---------|
| pandas | â‰¥1.0 | Data manipulation and analysis |
| scikit-learn | â‰¥0.24 | Machine learning algorithms |
| nltk | â‰¥3.5 | Natural language processing |
| joblib | â‰¥1.0 | Model serialization |

### Installation
All dependencies are listed in `requirements.txt`:
```bash
pip install -r requirements.txt
```

## ðŸ”® Future Improvements

### Model Enhancements
- [ ] Implement ensemble methods (Random Forest, Gradient Boosting)
- [ ] Add support for other languages
- [ ] Use word embeddings (Word2Vec, GloVe, FastText)
- [ ] Implement deep learning models (LSTM, Transformer-based)
- [ ] Hyperparameter tuning with GridSearchCV/RandomSearchCV

### Feature Additions
- [ ] Web interface using Flask/Django
- [ ] REST API for model serving
- [ ] Real-time email/SMS monitoring
- [ ] Support for multiple languages
- [ ] Confidence scores for predictions
- [ ] User feedback loop for model improvement

### Data & Processing
- [ ] Handle class imbalance (SMOTE, class weights)
- [ ] Expand dataset with more recent messages
- [ ] Add context-aware preprocessing
- [ ] Handle emoji and special symbols better
- [ ] Multi-label classification (multiple spam categories)

### Deployment
- [ ] Docker containerization
- [ ] Cloud deployment (AWS, Google Cloud)
- [ ] Mobile app integration
- [ ] Database integration for message logging
- [ ] Monitoring and logging system

## ðŸ› ï¸ Troubleshooting

### Issue: FileNotFoundError when running predict.py
**Solution:** Run `main.py` first to generate the model and vectorizer files.

### Issue: NLTK stopwords not found
**Solution:** Download NLTK data:
```bash
python -c "import nltk; nltk.download('stopwords')"
```

### Issue: Module 'src' not found
**Solution:** Run scripts from project root directory and use correct import paths.

### Issue: Low accuracy on custom messages
**Solution:** 
- Ensure messages are in English
- Check for preprocessed message quality
- Consider retraining with more diverse data

## ðŸ“ License

This project is open source and available for educational purposes.

## ðŸ‘¤ Author

This project is completely done by Saran for learning NLP


## ðŸ“§ Contact & Support

For issues, questions, or suggestions, please open an issue or contact the project maintainer.

---

**Last Updated:** February 8, 2026

**Status:** âœ… Fully Functional and Ready for Production
